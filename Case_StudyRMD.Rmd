---
title: "Google Capstone Project"
author: "Jalen"
date: '2022-03-21'
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(tidyverse)  #helps wrangle data
library(lubridate)  #helps wrangle date attributes
library(ggplot2)  #helps visualize data
getwd() #displays your working directory

```


## STEP 1: COLLECT DATA

Upload Divvy datasets (csv files) here

```{r cars}
Feb22 <- read_csv("202202-divvy-tripdata.csv")
Jan22 <- read_csv("202201-divvy-tripdata.csv")
Dec21 <- read_csv("202112-divvy-tripdata.csv")
Nov21 <- read_csv("202111-divvy-tripdata.csv")
Oct21 <- read_csv("202110-divvy-tripdata.csv")
Sept21 <- read_csv("202109-divvy-tripdata.csv")
Aug21 <- read_csv("202108-divvy-tripdata.csv")
July21 <- read_csv("202107-divvy-tripdata.csv")
June21 <- read_csv("202106-divvy-tripdata.csv")
May21 <- read_csv("202105-divvy-tripdata.csv")
Apr21 <- read_csv("202104-divvy-tripdata.csv")
Mar21 <- read_csv("202103-divvy-tripdata.csv")

```

Next we seperate the files into 5 different datasets to check for any differences. 

```{r}
Q1_21 <- rbind(Mar21)
Q2_21 <- rbind(Apr21, May21, June21)
Q3_21 <- rbind(July21, Aug21, Sept21)
Q4_21 <- rbind(Oct21, Nov21, Dec21)
Q1_22 <- rbind(Jan22, Feb22)
```

## STEP 2: WRANGLE DATA AND COMBINE INTO SINGLE FILE

Compare column names each of the files
While the names don't have to be in the same order, they DO need to match perfectly before we can use a command to join them into one file

```{r}
colnames(Q1_21)
colnames(Q2_21)
colnames(Q3_21)
colnames(Q4_21)
colnames(Q1_22)
```

Inspect the dataframes and look for incongruities
```{r}
str(Q1_21)
str(Q4_21)
str(Q3_21)
str(Q2_21)
str(Q1_22)
```

Stack individual quarter's data frames into one big data frame
```{r}
all_trips <- bind_rows(Q1_21, Q2_21, Q3_21, Q4_21, Q1_22)
```

Remove lat, and long fields as this data was dropped beginning in 2020
```{r}
all_trips <- all_trips %>%  
  select(-c(start_lat, start_lng, end_lat, end_lng))
```

## STEP 3: CLEAN UP AND ADD DATA TO PREPARE FOR ANALYSIS

Inspect the new table that has been created
```{r}
colnames(all_trips)  #List of column names
nrow(all_trips)  #How many rows are in data frame?
dim(all_trips)  #Dimensions of the data frame?
head(all_trips)  #See the first 6 rows of data frame.  Also tail(all_trips)
str(all_trips)  #See list of columns and data types (numeric, character, etc)
summary(all_trips)  #Statistical summary of data. Mainly for numeric
```

There are a few problems we will need to fix:

(1) The data can only be aggregated at the ride-level, which is too granular. We will want to add some additional columns of data -- such as day, month, year -- that provide additional opportunities to aggregate the data.
(2) We will want to add a calculated field for length of ride since the 2020Q1 data did not have the "trip_duration" column. We will add "ride_length" to the entire data frame for consistency.
(3) There are some rides where trip_duration shows up as negative, including several hundred rides where Divvy took bikes out of circulation for Quality Control reasons. We will want to delete these rides.

Check to make sure the proper number of observations were reassigned
```{r}
table(all_trips$member_casual)
```

Add columns that list the date, month, day, and year of each ride

This will allow us to aggregate ride data for each month, day, or year ... before completing these operations we could only aggregate at the ride level

https://www.statmethods.net/input/dates.html more on date formats in R found at that link
```{r}
all_trips$date <- as.Date(all_trips$started_at) #The default format is yyyy-mm-dd
all_trips$month <- format(as.Date(all_trips$date), "%m")
all_trips$day <- format(as.Date(all_trips$date), "%d")
all_trips$year <- format(as.Date(all_trips$date), "%Y")
all_trips$day_of_week <- format(as.Date(all_trips$date), "%A")
```

Add a "ride_length" calculation to all_trips (in seconds)
https://stat.ethz.ch/R-manual/R-devel/library/base/html/difftime.html
```{r}
all_trips$ride_length <- difftime(all_trips$ended_at,all_trips$started_at)
```

Inspect the structure of the columns
```{r}
str(all_trips)
```

Convert "ride_length" from Factor to numeric so we can run calculations on the data
```{r}
is.factor(all_trips$ride_length)
all_trips$ride_length <- as.numeric(as.character(all_trips$ride_length))
is.numeric(all_trips$ride_length)
```

Remove "bad" data
The dataframe includes a few hundred entries when bikes were taken out of docks and checked for quality by Divvy or ride_length was negative
We will create a new version of the dataframe (v2) since data is being removed
https://www.datasciencemadesimple.com/delete-or-drop-rows-in-r-with-conditions-2/
```{r}
all_trips_v2 <- all_trips[!(all_trips$start_station_name == "HQ QR" | all_trips$ride_length<0),]
# Take out any NA values so that there aren't any errors
all_trips_v2 <- na.omit(all_trips_v2)

```

## STEP 4: CONDUCT DESCRIPTIVE ANALYSIS

Descriptive analysis on ride_length (all figures in seconds)

```{r}
mean(all_trips_v2$ride_length) #straight average (total ride length / rides)
median(all_trips_v2$ride_length) #midpoint number in the ascending array of ride lengths
max(all_trips_v2$ride_length) #longest ride
min(all_trips_v2$ride_length) #shortest ride
```

You can condense the four lines above to one line using summary() on the specific attribute
```{r}
summary(all_trips_v2$ride_length)
```

Compare members and casual users

```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = mean)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = median)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = max)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = min)
```

See the average ride time by each day for members vs casual users
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
```

Notice that the days of the week are out of order. Let's fix that.
```{r}
all_trips_v2$day_of_week <- ordered(all_trips_v2$day_of_week, levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
```

Now, let's run the average ride time by each day for members vs casual users
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
```

Analyze ridership data by type and weekday
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%  #creates weekday field using wday()
  group_by(member_casual, weekday) %>%  #groups by usertype and weekday
  summarise(number_of_rides = n()                            #calculates the number of rides and average duration 
            ,average_duration = mean(ride_length)) %>%         # calculates the average duration
  arrange(member_casual, weekday)                                # sorts
```

Let's visualize the number of rides by rider type
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")
```

Let's create a visualization for average duration
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")
```

## STEP 5: EXPORT SUMMARY FILE FOR FURTHER ANALYSIS

```{r}
counts <- aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
write.csv(counts, "\\Users\\jday2\\Desktop\\Data\\Case Study\\Case_Study.csv")
```

